{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRptZY+aJuxryR+sJMGdsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManojKurapati/Audio_synthesis_Neuralnetwork/blob/main/youtube_transcriber_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKyEE5xVzbYT",
        "outputId": "6fb8e6a6-a759-4249-ac3d-7be99acedd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-49da7e62-4d54-2199-1243-2997455bd494)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTorch: 2.6.0+cu124 | Torchaudio: 2.6.0+cu124 | Python: 3.11.13\n"
          ]
        }
      ],
      "source": [
        "#@title GPU + deps\n",
        "!nvidia-smi -L || true\n",
        "!pip -q install yt-dlp pydub matplotlib tqdm\n",
        "\n",
        "import torch, torchaudio, platform\n",
        "print(\"Torch:\", torch.__version__, \"| Torchaudio:\", torchaudio.__version__, \"| Python:\", platform.python_version())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, math, copy, argparse, random\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio.datasets import YESNO\n",
        "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def nowdir(prefix=\"runs\"):\n",
        "    import datetime as dt\n",
        "    ts = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    out = os.path.join(prefix, ts)\n",
        "    os.makedirs(out, exist_ok=True)\n",
        "    return out\n",
        "\n",
        "def save_jsonl(path: str, record: Dict):\n",
        "    with open(path, \"a\") as f:\n",
        "        f.write(json.dumps(record) + \"\\n\")\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    data_root: str = \"./data\"\n",
        "    sample_rate: int = 16000\n",
        "    n_mels: int = 80\n",
        "    n_fft: int = 400\n",
        "    hop_length: int = 160\n",
        "    win_length: int = 400\n",
        "    epochs: int = 15\n",
        "    batch_size: int = 16\n",
        "    lr: float = 2e-3\n",
        "    weight_decay: float = 1e-4\n",
        "    hidden_size: int = 256\n",
        "    num_layers: int = 3\n",
        "    dropout: float = 0.1\n",
        "    grad_clip: float = 5.0\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    num_workers: int = 2\n",
        "    seed: int = 42\n",
        "    log_every: int = 50\n",
        "\n",
        "cfg = Config()\n",
        "cfg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXlvTkerE2d5",
        "outputId": "cfdac3dc-4cf4-4a0c-8882-833ea0113228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Config(data_root='./data', sample_rate=16000, n_mels=80, n_fft=400, hop_length=160, win_length=400, epochs=15, batch_size=16, lr=0.002, weight_decay=0.0001, hidden_size=256, num_layers=3, dropout=0.1, grad_clip=5.0, device='cuda', num_workers=2, seed=42, log_every=50)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharTokenizer:\n",
        "    \"\"\"Char-level tokenizer for CTC. idx 0 reserved for <blank>.\n",
        "       Lowercases text; unknowns -> space.\"\"\"\n",
        "    def __init__(self, vocab: str):\n",
        "        self.vocab = [\"<blank>\"] + list(vocab)\n",
        "        self.char2idx = {c: i for i, c in enumerate(self.vocab)}\n",
        "        self.blank_id = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def build_from_corpus(texts: List[str]):\n",
        "        allowed = set(list(\"abcdefghijklmnopqrstuvwxyz0123456789 '.,?!-:;()\"))\n",
        "        chars = set()\n",
        "        for t in texts:\n",
        "            for ch in t.lower():\n",
        "                if ch in allowed:\n",
        "                    chars.add(ch)\n",
        "                elif ch == \"\\t\":\n",
        "                    continue\n",
        "                else:\n",
        "                    chars.add(\" \")\n",
        "        chars.add(\" \")\n",
        "        vocab = \"\".join(sorted(list(chars)))\n",
        "        return CharTokenizer(vocab)\n",
        "\n",
        "    def encode(self, text: str) -> List[int]:\n",
        "        text = text.lower()\n",
        "        out = []\n",
        "        for ch in text:\n",
        "            if ch not in self.char2idx: ch = \" \"\n",
        "            out.append(self.char2idx[ch])\n",
        "        return out\n",
        "\n",
        "    def decode(self, ids: List[int], collapse_repeats=True) -> str:\n",
        "        res, prev = [], None\n",
        "        for i in ids:\n",
        "            if i == self.blank_id:\n",
        "                prev = None\n",
        "                continue\n",
        "            if collapse_repeats and i == prev:\n",
        "                continue\n",
        "            res.append(self.vocab[i])\n",
        "            prev = i\n",
        "        return \"\".join(res).strip()\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self): return len(self.vocab)\n"
      ],
      "metadata": {
        "id": "RpKddThZHKUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MelSpecExtractor(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.mel = MelSpectrogram(\n",
        "            sample_rate=cfg.sample_rate,\n",
        "            n_fft=cfg.n_fft, hop_length=cfg.hop_length, win_length=cfg.win_length,\n",
        "            n_mels=cfg.n_mels, power=2.0, normalized=False, center=True\n",
        "        )\n",
        "        self.db = AmplitudeToDB(stype=\"power\")\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, wav: torch.Tensor, sr: int) -> torch.Tensor:\n",
        "        if sr != self.cfg.sample_rate:\n",
        "            wav = torchaudio.functional.resample(wav, sr, self.cfg.sample_rate)\n",
        "        feat = self.db(self.mel(wav))  # (n_mels, T)\n",
        "        mean = feat.mean(dim=-1, keepdim=True)\n",
        "        std  = feat.std(dim=-1, keepdim=True).clamp_min(1e-5)\n",
        "        return (feat - mean) / std\n",
        "\n",
        "class AN4Wrap(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, extractor: MelSpecExtractor, tokenizer: CharTokenizer):\n",
        "        self.ds = dataset; self.ext = extractor; self.tok = tokenizer\n",
        "\n",
        "    def __len__(self): return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        wav, sr, transcript, speaker_id, utt_id = self.ds[idx]\n",
        "        feat = self.ext(wav, sr)                     # (n_mels, T)\n",
        "        target = torch.tensor(self.tok.encode(transcript), dtype=torch.long)\n",
        "        return feat, transcript, target\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = sorted(batch, key=lambda x: x[0].shape[-1], reverse=True)\n",
        "    feats, texts, targets = zip(*batch)\n",
        "    input_lengths = torch.tensor([f.shape[-1] for f in feats], dtype=torch.long)\n",
        "    target_lengths = torch.tensor([t.numel() for t in targets], dtype=torch.long)\n",
        "    n_mels = feats[0].shape[0]\n",
        "    max_T = int(max([f.shape[-1] for f in feats]))\n",
        "    feat_pad = torch.zeros(len(feats), n_mels, max_T, dtype=torch.float32)\n",
        "    for i, f in enumerate(feats): feat_pad[i, :, : f.shape[-1]] = f\n",
        "    targets_cat = torch.cat(targets, dim=0)\n",
        "    return feat_pad, input_lengths, targets_cat, target_lengths, list(texts)\n"
      ],
      "metadata": {
        "id": "3OuBt02JHNGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CTCBiGRU(nn.Module):\n",
        "    def __init__(self, n_mels: int, hidden: int, layers: int, dropout: float, vocab_size: int):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=n_mels, hidden_size=hidden, num_layers=layers,\n",
        "            batch_first=True, bidirectional=True,\n",
        "            dropout=dropout if layers > 1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden * 2, vocab_size)\n",
        "\n",
        "    def forward(self, feats: torch.Tensor, lengths: torch.Tensor):\n",
        "        x = feats.transpose(1, 2)                            # (B,T,n_mels)\n",
        "        packed = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=True)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out, batch_first=True)  # (B,T,2H)\n",
        "        logits = self.fc(out).transpose(0, 1)                # (T,B,V)\n",
        "        return logits, lengths\n",
        "\n",
        "def _edit_distance(a: List[str], b: List[str]) -> int:\n",
        "    m, n = len(a), len(b)\n",
        "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
        "    for i in range(m+1): dp[i][0] = i\n",
        "    for j in range(n+1): dp[0][j] = j\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            cost = 0 if a[i-1] == b[j-1] else 1\n",
        "            dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
        "    return dp[m][n]\n",
        "\n",
        "def cer(ref: str, hyp: str) -> float:\n",
        "    rc, hc = list(ref.strip().lower()), list(hyp.strip().lower())\n",
        "    return 0.0 if len(rc)==0 and len(hc)==0 else _edit_distance(rc, hc)/max(1,len(rc))\n",
        "\n",
        "def wer(ref: str, hyp: str) -> float:\n",
        "    rw, hw = ref.strip().lower().split(), hyp.strip().lower().split()\n",
        "    return 0.0 if len(rw)==0 and len(hw)==0 else _edit_distance(rw, hw)/max(1,len(rw))\n",
        "\n",
        "def greedy_decode(logits: torch.Tensor, blank_id: int = 0) -> List[int]:\n",
        "    ids = logits.argmax(dim=-1).tolist()\n",
        "    out, prev = [], None\n",
        "    for i in ids:\n",
        "        if i == blank_id: prev = None; continue\n",
        "        if i == prev: continue\n",
        "        out.append(i); prev = i\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "-coxBfSjHPSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, scaler, device, tokenizer, log_every=50):\n",
        "    model.train()\n",
        "    total_loss, steps = 0.0, 0\n",
        "    t0 = time.time()\n",
        "    for step, (feats, in_lens, tgts, tgt_lens, texts) in enumerate(loader, 1):\n",
        "        feats, in_lens, tgts, tgt_lens = feats.to(device), in_lens.to(device), tgts.to(device), tgt_lens.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=device.startswith(\"cuda\")):\n",
        "            logits, out_lens = model(feats, in_lens)\n",
        "            loss = criterion(logits.log_softmax(2), tgts, out_lens, tgt_lens)\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        total_loss += loss.item(); steps += 1\n",
        "        if step % log_every == 0:\n",
        "            dt = time.time() - t0\n",
        "            print(f\"  step {step:05d} | loss {total_loss/steps:.4f} | dt {dt:.1f}s\")\n",
        "            t0 = time.time()\n",
        "    return total_loss / max(1, steps)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device, tokenizer):\n",
        "    model.eval()\n",
        "    tot_loss, n_batches = 0.0, 0\n",
        "    tot_cer, tot_wer, n_utts = 0.0, 0.0, 0\n",
        "    for feats, in_lens, tgts, tgt_lens, texts in loader:\n",
        "        feats, in_lens, tgts, tgt_lens = feats.to(device), in_lens.to(device), tgts.to(device), tgt_lens.to(device)\n",
        "        logits, out_lens = model(feats, in_lens)\n",
        "        loss = criterion(logits.log_softmax(2), tgts, out_lens, tgt_lens)\n",
        "        tot_loss += loss.item(); n_batches += 1\n",
        "\n",
        "        T,B,V = logits.shape\n",
        "        for b in range(B):\n",
        "            seq = logits[:, b, :]\n",
        "            ids = greedy_decode(seq, blank_id=tokenizer.blank_id)\n",
        "            hyp = tokenizer.decode(ids)\n",
        "            ref = texts[b]\n",
        "            tot_cer += cer(ref, hyp)\n",
        "            tot_wer += wer(ref, hyp)\n",
        "            n_utts += 1\n",
        "\n",
        "    return (tot_loss/max(1,n_batches),\n",
        "            tot_cer/max(1,n_utts),\n",
        "            tot_wer/max(1,n_utts))\n"
      ],
      "metadata": {
        "id": "FNVjdH8aHRd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(cfg.data_root, exist_ok=True)  # ensure the data directory exists\n",
        "\n",
        "set_seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "\n",
        "outdir = nowdir(\"runs\"); print(\"Saving to:\", outdir)\n",
        "\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "_tmp = YESNO(root=cfg.data_root, download=True)\n",
        "corpus = [\n",
        "    \" \".join(\"yes\" if int(x)==1 else \"no\" for x in labels)\n",
        "    for (_, _, labels) in _tmp\n",
        "]\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = CharTokenizer.build_from_corpus(corpus)\n",
        "print(\"Vocab size:\", tokenizer.vocab_size)\n",
        "\n",
        "# Inline wrapper for YESNO to produce (features, transcript, target_ids)\n",
        "class YesNoWrap(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, download, extractor, tokenizer):\n",
        "        self.ds = YESNO(root=root, download=download)\n",
        "        self.ext = extractor\n",
        "        self.tok = tokenizer\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    def __getitem__(self, idx):\n",
        "        wav, sr, labels = self.ds[idx]\n",
        "        transcript = \" \".join(\"yes\" if int(x)==1 else \"no\" for x in labels)\n",
        "        feat = self.ext(wav, sr)  # (n_mels, T)\n",
        "        feat = feat.squeeze(0) if feat.dim() == 3 else feat  # Ensure 2D\n",
        "        if feat.shape[0] != cfg.n_mels:\n",
        "            # Adjust mel dimension if mismatch\n",
        "            feat = torch.nn.functional.interpolate(feat.unsqueeze(0), size=(cfg.n_mels, feat.shape[1]), mode='bilinear', align_corners=False).squeeze(0)\n",
        "        target = torch.tensor(self.tok.encode(transcript), dtype=torch.long)\n",
        "        return feat, transcript, target\n",
        "\n",
        "# Feature extractor & dataset\n",
        "extractor = MelSpecExtractor(cfg)\n",
        "full_ds = YesNoWrap(root=cfg.data_root, download=False, extractor=extractor, tokenizer=tokenizer)\n",
        "\n",
        "# Train/Val split 80/20\n",
        "n = len(full_ds)\n",
        "n_train = int(0.8 * n)\n",
        "n_val = n - n_train\n",
        "train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=torch.Generator().manual_seed(cfg.seed))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
        "                          num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,\n",
        "                          num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "# --- Model / Optim / Loss ---\n",
        "model = CTCBiGRU(cfg.n_mels, cfg.hidden_size, cfg.num_layers, cfg.dropout, tokenizer.vocab_size).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "criterion = nn.CTCLoss(blank=tokenizer.blank_id, zero_infinity=True)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=device.startswith(\"cuda\"))\n",
        "\n",
        "best_cer = float(\"inf\")\n",
        "metrics_path = os.path.join(outdir, \"metrics.jsonl\")\n",
        "\n",
        "for epoch in range(1, cfg.epochs+1):\n",
        "    print(f\"\\nEpoch {epoch}/{cfg.epochs}\")\n",
        "    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, tokenizer, cfg.log_every)\n",
        "    val_loss, val_cer, val_wer = evaluate(model, val_loader, criterion, device, tokenizer)\n",
        "    char_acc = 1.0 - val_cer\n",
        "    rec = {\"epoch\": epoch, \"train_loss\": tr_loss, \"val_loss\": val_loss,\n",
        "           \"val_cer\": val_cer, \"val_wer\": val_wer, \"char_accuracy\": char_acc}\n",
        "    save_jsonl(metrics_path, rec)\n",
        "    print(f\"  train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | CER={val_cer:.3f} | WER={val_wer:.3f} | CharAcc={char_acc:.3f}\")\n",
        "\n",
        "    ckpt = {\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"config\": asdict(cfg),\n",
        "        \"tokenizer_vocab\": \"\".join(tokenizer.vocab[1:]),\n",
        "        \"blank_id\": tokenizer.blank_id,\n",
        "    }\n",
        "    torch.save(ckpt, os.path.join(outdir, \"last.ckpt\"))\n",
        "    if val_cer < best_cer:\n",
        "        best_cer = val_cer\n",
        "        torch.save(ckpt, os.path.join(outdir, \"best.ckpt\"))\n",
        "        print(f\"  ✅ New best CER={best_cer:.3f} -> saved best.ckpt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed8v0UulHTl1",
        "outputId": "1c16cde1-e45f-4dc5-8148-6aad419c9fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Saving to: runs/20250811-123745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.49M/4.49M [00:01<00:00, 2.43MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-670550748.py:63: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=device.startswith(\"cuda\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3054475909.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=device.startswith(\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss=36.2670 | val_loss=37.0590 | CER=0.905 | WER=1.052 | CharAcc=0.095\n",
            "  ✅ New best CER=0.905 -> saved best.ckpt\n",
            "\n",
            "Epoch 2/15\n",
            "  train_loss=18.2267 | val_loss=5.1383 | CER=0.965 | WER=1.000 | CharAcc=0.035\n",
            "\n",
            "Epoch 3/15\n",
            "  train_loss=4.6777 | val_loss=4.5976 | CER=0.621 | WER=1.000 | CharAcc=0.379\n",
            "  ✅ New best CER=0.621 -> saved best.ckpt\n",
            "\n",
            "Epoch 4/15\n",
            "  train_loss=3.6893 | val_loss=2.3717 | CER=0.463 | WER=1.021 | CharAcc=0.537\n",
            "  ✅ New best CER=0.463 -> saved best.ckpt\n",
            "\n",
            "Epoch 5/15\n",
            "  train_loss=1.9628 | val_loss=2.0811 | CER=0.511 | WER=0.865 | CharAcc=0.489\n",
            "\n",
            "Epoch 6/15\n",
            "  train_loss=1.6848 | val_loss=1.7045 | CER=0.461 | WER=0.854 | CharAcc=0.539\n",
            "  ✅ New best CER=0.461 -> saved best.ckpt\n",
            "\n",
            "Epoch 7/15\n",
            "  train_loss=1.3720 | val_loss=1.4762 | CER=0.579 | WER=0.865 | CharAcc=0.421\n",
            "\n",
            "Epoch 8/15\n",
            "  train_loss=1.3054 | val_loss=1.3371 | CER=0.429 | WER=0.812 | CharAcc=0.571\n",
            "  ✅ New best CER=0.429 -> saved best.ckpt\n",
            "\n",
            "Epoch 9/15\n",
            "  train_loss=1.2303 | val_loss=1.4007 | CER=0.489 | WER=0.750 | CharAcc=0.511\n",
            "\n",
            "Epoch 10/15\n",
            "  train_loss=1.1831 | val_loss=1.2769 | CER=0.399 | WER=0.760 | CharAcc=0.601\n",
            "  ✅ New best CER=0.399 -> saved best.ckpt\n",
            "\n",
            "Epoch 11/15\n",
            "  train_loss=0.9447 | val_loss=1.1111 | CER=0.402 | WER=0.875 | CharAcc=0.598\n",
            "\n",
            "Epoch 12/15\n",
            "  train_loss=0.9279 | val_loss=0.8664 | CER=0.255 | WER=0.542 | CharAcc=0.745\n",
            "  ✅ New best CER=0.255 -> saved best.ckpt\n",
            "\n",
            "Epoch 13/15\n",
            "  train_loss=0.7656 | val_loss=0.6600 | CER=0.217 | WER=0.510 | CharAcc=0.783\n",
            "  ✅ New best CER=0.217 -> saved best.ckpt\n",
            "\n",
            "Epoch 14/15\n",
            "  train_loss=0.6294 | val_loss=0.9919 | CER=0.322 | WER=0.625 | CharAcc=0.678\n",
            "\n",
            "Epoch 15/15\n",
            "  train_loss=0.6754 | val_loss=0.6556 | CER=0.217 | WER=0.448 | CharAcc=0.783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(cfg.data_root, exist_ok=True)  # ensure the data directory exists\n",
        "\n",
        "set_seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "\n",
        "outdir = nowdir(\"runs\"); print(\"Saving to:\", outdir)\n",
        "\n",
        "# --- Use torchaudio YESNO dataset ---\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchaudio.datasets import YESNO # Import YESNO dataset\n",
        "\n",
        "# Build corpus (\"yes\"/\"no\" tokens) for tokenizer\n",
        "_tmp = YESNO(root=cfg.data_root, download=True)\n",
        "corpus = [\n",
        "    \" \".join(\"yes\" if int(x)==1 else \"no\" for x in labels)\n",
        "    for (_, _, labels) in _tmp\n",
        "]\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = CharTokenizer.build_from_corpus(corpus)\n",
        "print(\"Vocab size:\", tokenizer.vocab_size)\n",
        "\n",
        "# Inline wrapper for YESNO to produce (features, transcript, target_ids)\n",
        "class YesNoWrap(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, extractor, tokenizer):\n",
        "        self.ds = dataset\n",
        "        self.ext = extractor\n",
        "        self.tok = tokenizer\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    def __getitem__(self, idx):\n",
        "        wav, sr, labels = self.ds[idx]\n",
        "        transcript = \" \".join(\"yes\" if int(x)==1 else \"no\" for x in labels)\n",
        "        feat = self.ext(wav, sr)  # (n_mels, T)\n",
        "        # Ensure feature is 2D (n_mels, T)\n",
        "        feat = feat.squeeze(0) if feat.dim() == 3 else feat\n",
        "        if feat.shape[0] != cfg.n_mels:\n",
        "            # Adjust mel dimension if mismatch - this might not be the best approach,\n",
        "            # but it attempts to handle potential shape inconsistencies.\n",
        "            # A better approach might be to ensure the extractor produces the correct shape.\n",
        "            # For now, let's try to interpolate if needed.\n",
        "            try:\n",
        "                feat = torch.nn.functional.interpolate(feat.unsqueeze(0), size=(cfg.n_mels, feat.shape[1]), mode='bilinear', align_corners=False).squeeze(0)\n",
        "            except RuntimeError:\n",
        "                 # Fallback if interpolation fails (e.g., time dimension is 1)\n",
        "                 print(f\"Warning: Could not interpolate feature shape for index {idx}. Expected {cfg.n_mels}, got {feat.shape[0]}. Skipping interpolation.\")\n",
        "                 # You might want to handle this case differently, e.g., pad or skip the sample\n",
        "                 pass # For now, just pass and hope the rest of the pipeline can handle it\n",
        "\n",
        "\n",
        "        target = torch.tensor(self.tok.encode(transcript), dtype=torch.long)\n",
        "        return feat, transcript, target\n",
        "\n",
        "# Feature extractor & dataset\n",
        "extractor = MelSpecExtractor(cfg)\n",
        "# Load the YESNO dataset without downloading again if already present\n",
        "full_ds = YESNO(root=cfg.data_root, download=False)\n",
        "wrapped_ds = YesNoWrap(dataset=full_ds, extractor=extractor, tokenizer=tokenizer)\n",
        "\n",
        "\n",
        "# Train/Val split 80/20\n",
        "n = len(wrapped_ds)\n",
        "n_train = int(0.8 * n)\n",
        "n_val = n - n_train\n",
        "train_ds, val_ds = random_split(wrapped_ds, [n_train, n_val], generator=torch.Generator().manual_seed(cfg.seed))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
        "                          num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,\n",
        "                          num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "\n",
        "# --- Model / Optim / Loss ---\n",
        "model = CTCBiGRU(cfg.n_mels, cfg.hidden_size, cfg.num_layers, cfg.dropout, tokenizer.vocab_size).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "criterion = nn.CTCLoss(blank=tokenizer.blank_id, zero_infinity=True)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=device.startswith(\"cuda\"))\n",
        "\n",
        "best_cer = float(\"inf\")\n",
        "metrics_path = os.path.join(outdir, \"metrics.jsonl\")\n",
        "\n",
        "for epoch in range(1, cfg.epochs+1):\n",
        "    print(f\"\\nEpoch {epoch}/{cfg.epochs}\")\n",
        "    tr_loss = train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, tokenizer, cfg.log_every)\n",
        "    val_loss, val_cer, val_wer = evaluate(model, val_loader, criterion, device, tokenizer)\n",
        "    char_acc = 1.0 - val_cer\n",
        "    rec = {\"epoch\": epoch, \"train_loss\": tr_loss, \"val_loss\": val_loss,\n",
        "           \"val_cer\": val_cer, \"val_wer\": val_wer, \"char_accuracy\": char_acc}\n",
        "    save_jsonl(metrics_path, rec)\n",
        "    print(f\"  train_loss={tr_loss:.4f} | val_loss={val_loss:.4f} | CER={val_cer:.3f} | WER={val_wer:.3f} | CharAcc={char_acc:.3f}\")\n",
        "\n",
        "    ckpt = {\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"config\": asdict(cfg),\n",
        "        \"tokenizer_vocab\": \"\".join(tokenizer.vocab[1:]),\n",
        "        \"blank_id\": tokenizer.blank_id,\n",
        "    }\n",
        "    torch.save(ckpt, os.path.join(outdir, \"last.ckpt\"))\n",
        "    if val_cer < best_cer:\n",
        "        best_cer = val_cer\n",
        "        torch.save(ckpt, os.path.join(outdir, \"best.ckpt\"))\n",
        "        print(f\"  ✅ New best CER={best_cer:.3f} -> saved best.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oUa4vjgI3af",
        "outputId": "c031a49f-bd93-4e12-ca4e-22b742c05336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Saving to: runs/20250811-124401\n",
            "Vocab size: 7\n",
            "\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1732584801.py:81: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=device.startswith(\"cuda\"))\n",
            "/tmp/ipython-input-3054475909.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=device.startswith(\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss=36.2670 | val_loss=37.0590 | CER=0.905 | WER=1.052 | CharAcc=0.095\n",
            "  ✅ New best CER=0.905 -> saved best.ckpt\n",
            "\n",
            "Epoch 2/15\n",
            "  train_loss=18.2267 | val_loss=5.1383 | CER=0.965 | WER=1.000 | CharAcc=0.035\n",
            "\n",
            "Epoch 3/15\n",
            "  train_loss=4.6777 | val_loss=4.5976 | CER=0.621 | WER=1.000 | CharAcc=0.379\n",
            "  ✅ New best CER=0.621 -> saved best.ckpt\n",
            "\n",
            "Epoch 4/15\n",
            "  train_loss=3.6893 | val_loss=2.3717 | CER=0.463 | WER=1.021 | CharAcc=0.537\n",
            "  ✅ New best CER=0.463 -> saved best.ckpt\n",
            "\n",
            "Epoch 5/15\n",
            "  train_loss=1.9628 | val_loss=2.0811 | CER=0.511 | WER=0.865 | CharAcc=0.489\n",
            "\n",
            "Epoch 6/15\n",
            "  train_loss=1.6848 | val_loss=1.7045 | CER=0.461 | WER=0.854 | CharAcc=0.539\n",
            "  ✅ New best CER=0.461 -> saved best.ckpt\n",
            "\n",
            "Epoch 7/15\n",
            "  train_loss=1.3720 | val_loss=1.4762 | CER=0.579 | WER=0.865 | CharAcc=0.421\n",
            "\n",
            "Epoch 8/15\n",
            "  train_loss=1.3054 | val_loss=1.3371 | CER=0.429 | WER=0.812 | CharAcc=0.571\n",
            "  ✅ New best CER=0.429 -> saved best.ckpt\n",
            "\n",
            "Epoch 9/15\n",
            "  train_loss=1.2303 | val_loss=1.4007 | CER=0.489 | WER=0.750 | CharAcc=0.511\n",
            "\n",
            "Epoch 10/15\n",
            "  train_loss=1.1831 | val_loss=1.2769 | CER=0.399 | WER=0.760 | CharAcc=0.601\n",
            "  ✅ New best CER=0.399 -> saved best.ckpt\n",
            "\n",
            "Epoch 11/15\n",
            "  train_loss=0.9447 | val_loss=1.1111 | CER=0.402 | WER=0.875 | CharAcc=0.598\n",
            "\n",
            "Epoch 12/15\n",
            "  train_loss=0.9279 | val_loss=0.8664 | CER=0.255 | WER=0.542 | CharAcc=0.745\n",
            "  ✅ New best CER=0.255 -> saved best.ckpt\n",
            "\n",
            "Epoch 13/15\n",
            "  train_loss=0.7656 | val_loss=0.6600 | CER=0.217 | WER=0.510 | CharAcc=0.783\n",
            "  ✅ New best CER=0.217 -> saved best.ckpt\n",
            "\n",
            "Epoch 14/15\n",
            "  train_loss=0.6294 | val_loss=0.9919 | CER=0.322 | WER=0.625 | CharAcc=0.678\n",
            "\n",
            "Epoch 15/15\n",
            "  train_loss=0.6754 | val_loss=0.6556 | CER=0.217 | WER=0.448 | CharAcc=0.783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot loss curve\n",
        "rows = [json.loads(x) for x in open(metrics_path)]\n",
        "xs = [r[\"epoch\"] for r in rows]\n",
        "tr = [r[\"train_loss\"] for r in rows]\n",
        "vl = [r[\"val_loss\"] for r in rows]\n",
        "plt.figure()\n",
        "plt.plot(xs, tr, label=\"train_loss\")\n",
        "plt.plot(xs, vl, label=\"val_loss\")\n",
        "plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.title(\"Loss curve\")\n",
        "plt.grid(True); plt.show()\n",
        "rows[-1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "YfVjK5TiKOna",
        "outputId": "cb0976be-5418-4edb-b289-e49d58c136b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 15,\n",
              " 'train_loss': 0.6754006147384644,\n",
              " 'val_loss': 0.6556249260902405,\n",
              " 'val_cer': 0.21669854836521504,\n",
              " 'val_wer': 0.4479166666666667,\n",
              " 'char_accuracy': 0.7833014516347849}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference Helpers\n",
        "import subprocess, tempfile, urllib.parse, requests\n",
        "\n",
        "def download_media_to_wav(url: str, out_wav: str, sample_rate: int = 16000):\n",
        "    ext = os.path.splitext(urllib.parse.urlparse(url).path)[1].lower()\n",
        "    if ext in [\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\"]:\n",
        "        r = requests.get(url, timeout=60); r.raise_for_status()\n",
        "        tmp = out_wav + \".tmp\"\n",
        "        with open(tmp, \"wb\") as f: f.write(r.content)\n",
        "        wav, sr = torchaudio.load(tmp)\n",
        "        if sr != sample_rate:\n",
        "            wav = torchaudio.functional.resample(wav, sr, sample_rate)\n",
        "        torchaudio.save(out_wav, wav, sample_rate); os.remove(tmp)\n",
        "    else:\n",
        "        # For YouTube or unknown extensions -> yt-dlp (requires ffmpeg; Colab has it)\n",
        "        cmd = [\"yt-dlp\",\"-x\",\"--audio-format\",\"wav\",\"--audio-quality\",\"0\",\"-o\",out_wav,url]\n",
        "        subprocess.run(cmd, check=True)\n",
        "\n",
        "def chunk_tensor(wav: torch.Tensor, sr: int, chunk_sec=20, overlap_sec=2):\n",
        "    T = wav.shape[-1]; chunk_len = int(chunk_sec*sr); hop = int((chunk_sec-overlap_sec)*sr)\n",
        "    if hop <= 0: hop = chunk_len\n",
        "    out, start = [], 0\n",
        "    while start < T:\n",
        "        end = min(T, start+chunk_len)\n",
        "        out.append(wav[:, start:end])\n",
        "        if end == T: break\n",
        "        start += hop\n",
        "    return out\n",
        "\n",
        "def load_checkpoint(ckpt_path: str, device: str):\n",
        "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
        "    cfgc = ckpt[\"config\"]\n",
        "    vocab = ckpt[\"tokenizer_vocab\"]; blank_id = ckpt.get(\"blank_id\", 0)\n",
        "    tokenizer = CharTokenizer(vocab)\n",
        "    model = CTCBiGRU(cfgc[\"n_mels\"], cfgc[\"hidden_size\"], cfgc[\"num_layers\"], cfgc[\"dropout\"], len(tokenizer.vocab)).to(device)\n",
        "    model.load_state_dict(ckpt[\"model_state\"], strict=True)\n",
        "    model.eval()\n",
        "    mel = MelSpectrogram(sample_rate=cfgc[\"sample_rate\"], n_fft=cfgc[\"n_fft\"], hop_length=cfgc[\"hop_length\"],\n",
        "                         win_length=cfgc[\"win_length\"], n_mels=cfgc[\"n_mels\"], power=2.0, normalized=False, center=True)\n",
        "    db  = AmplitudeToDB(stype=\"power\")\n",
        "    return model, tokenizer, mel, db, cfgc[\"sample_rate\"]\n"
      ],
      "metadata": {
        "id": "0yDVgnjlKXkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transcribe a local file\n",
        "ckpt_path = os.path.join(outdir, \"best.ckpt\")  # or paste a previous run path\n",
        "audio_path = \"'/Users/klm/Desktop/New Recording 2.m4a'\"  #@param {type:\"string\"}\n",
        "chunk_sec = 20.0 #@param {type:\"number\"}\n",
        "overlap_sec = 2.0 #@param {type:\"number\"}\n",
        "\n",
        "assert os.path.exists(ckpt_path), \"best.ckpt not found. Train first or set a valid path.\"\n",
        "assert os.path.exists(audio_path), \"Set a valid local audio path.\"\n",
        "\n",
        "model, tokenizer, mel, db, sr_expected = load_checkpoint(ckpt_path, cfg.device)\n",
        "wav, sr = torchaudio.load(audio_path)\n",
        "if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
        "if sr != sr_expected: wav = torchaudio.functional.resample(wav, sr, sr_expected); sr = sr_expected\n",
        "\n",
        "chunks = chunk_tensor(wav, sr, chunk_sec=chunk_sec, overlap_sec=overlap_sec)\n",
        "final = []\n",
        "with torch.no_grad():\n",
        "    for ch in chunks:\n",
        "        feat = db(mel(ch))\n",
        "        m = feat.mean(dim=-1, keepdim=True); s = feat.std(dim=-1, keepdim=True).clamp_min(1e-5)\n",
        "        feat = (feat - m) / s\n",
        "        feats = feat.unsqueeze(0).to(cfg.device)              # (1,n_mels,T)\n",
        "        lens  = torch.tensor([feats.shape[-1]], dtype=torch.long).to(cfg.device)\n",
        "        logits, _ = model(feats, lens)                        # (T,1,V)\n",
        "        ids = greedy_decode(logits[:,0,:], tokenizer.blank_id)\n",
        "        final.append(tokenizer.decode(ids))\n",
        "\n",
        "print(\"\\n--- TRANSCRIPT ---\\n\")\n",
        "print(\" \".join([t for t in final if t]).strip())\n",
        "print(\"\\n------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "xLaa50MOKcPB",
        "outputId": "dd60217a-357c-412f-f1ad-aafef81ff543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Set a valid local audio path.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2708168426.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"best.ckpt not found. Train first or set a valid path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Set a valid local audio path.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_expected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Set a valid local audio path."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transcribe from a URL (podcast/mp3/YouTube)\n",
        "ckpt_path = os.path.join(outdir, \"best.ckpt\")  # or paste a previous run path\n",
        "url = \"https://www.youtube.com/watch?v=jjnVFJIwHas\" #@param {type:\"string\"}\n",
        "chunk_sec = 20.0 #@param {type:\"number\"}\n",
        "overlap_sec = 2.0 #@param {type:\"number\"}\n",
        "\n",
        "assert os.path.exists(ckpt_path), \"best.ckpt not found. Train first or set a valid path.\"\n",
        "assert url, \"Provide a URL.\"\n",
        "\n",
        "model, tokenizer, mel, db, sr_expected = load_checkpoint(ckpt_path, cfg.device)\n",
        "tmp_wav = os.path.join(tempfile.gettempdir(), \"asr_infer.wav\")\n",
        "download_media_to_wav(url, tmp_wav, sample_rate=sr_expected)\n",
        "\n",
        "wav, sr = torchaudio.load(tmp_wav)\n",
        "if wav.shape[0] > 1: wav = wav.mean(dim=0, keepdim=True)\n",
        "if sr != sr_expected: wav = torchaudio.functional.resample(wav, sr, sr_expected); sr = sr_expected\n",
        "\n",
        "chunks = chunk_tensor(wav, sr, chunk_sec=chunk_sec, overlap_sec=overlap_sec)\n",
        "final = []\n",
        "with torch.no_grad():\n",
        "    for ch in chunks:\n",
        "        feat = db(mel(ch))\n",
        "        m = feat.mean(dim=-1, keepdim=True); s = feat.std(dim=-1, keepdim=True).clamp_min(1e-5)\n",
        "        feat = (feat - m) / s\n",
        "        # Removed unsqueeze(0) here as the model expects (batch_size, n_mels, time_steps)\n",
        "        # and we are processing chunks one by one, so batch_size is 1 implicitly.\n",
        "        feats = feat.to(cfg.device)\n",
        "        lens  = torch.tensor([feats.shape[-1]], dtype=torch.long).to(cfg.device)\n",
        "        logits, _ = model(feats, lens)\n",
        "        ids = greedy_decode(logits[:,0,:], tokenizer.blank_id)\n",
        "        final.append(tokenizer.decode(ids))\n",
        "\n",
        "print(\"\\n--- TRANSCRIPT ---\\n\")\n",
        "print(\" \".join([t for t in final if t]).strip())\n",
        "print(\"\\n------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuWkgxqlKgWS",
        "outputId": "85427a84-5279-4854-acef-c862a7ff89c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TRANSCRIPT ---\n",
            "\n",
            "es yes no no o nonyes ys yes yes yes yes yo o es yes yes y no es yes ys yoes o yes yes yes yes yes o yes yo yesyes ys es yes o no o yes o yes yes es yes no n yo yono o es yo yes yo yes y es yes yes yes yes yes yes yes yes o yes yes yes yoses yes no no yes s yo eo yes es yes yes yes yo oyo yes o eos yes yes o yo e es yes no es yes yes y oyes yes yo o o yo yo es o yes no yes yses yes es es yses yno yes s no yes es yesyes es yes yo no s yesyes yes yo yo yes yes yo o yes yes yo es yes yo no es yes yes yeso yno o yso yes o n yes yes es yes o yes es yes yo y es yes yes o yes yes yo no no oyoyes yoes es es o oyes yes yes yo es yones y o yes yesyes yes yes yes o ys yoyes yes yeso yo s es yes o no nes n yes yes yes yes yes yo o yno es yes o eo no yesyes yes ys yesyes yes n yes yes yes yes no o yes yo o no yes no yes no yoes yes ysyes ys yo ysyes yes es yo yo yes yes yes es so yes yo es n yes s es o o ys o s o o es yes yes yos es o ysyes yes yes ysyes yes yes ys o os yes yos s o yes ysos yos yso yes yes yes yes yes yes yes yes yes yes y yes yes yeo yes yes yo o yns yes ys es yes yes yes yes yes yes yso yes os es yes yes ys esyes yes yes ysyes yes yses yes yes n yes yes yo yes os yono o o no es yno yes yes yes yo yes yes yes yes s yes yes o no s yes yes yso no n yes yes o yes yes yso yes y es yo o yes yes yes yes yes yes yes ysyes so yes es yes yo es o yes yo y ns s yes yes yoys yo yes yes yes yes yes es yes yes es yosyesyes yesyes o yoyes y oyes es yes yes yes yes yes s es yes yes yes yes yos es no yes yes yo no no o o no o o es ynoyes yes yes yo yono syes yes ys yes yes yes yes yes yes yeo es yes no yes yes yes o yes o es s yesnes yoyo yes e s yes yo o o es yes es y yes ys yes yes yes yes yes ysoyes no o es yes yes yes yes yo es yes yso es ys yes yes no os ysyes yes ysyo yes o ysys yes es so sono no s y yes oso yes yes s o yes yes yes esys ono noes oes o yo yes o yes yes es yo no no yes yes no no yes yes ysyeo yoyes yes yes o o ysyes yo yes yo yses yes yes o nes y esyes o o yes yes yes o no s yes yono yes nono yes yes yes no es o yes yes yo es ono yes o o o yes oes yo ys yoso o yes yes ys es ys yes ysyes yo yes ys es o no ys yes y es yes yes yes yes yes yes oynonos yses n no no ysyes yso ys es o syes ys yes yes ens ys o es yes yes yes yoyes yo yo yes es yo yes yes yes yes yes yos no yeo yes yses eo yes es yes yo o yes o no o yes os yes yes yes es yes ys yes ysyes yo y es yes yes yo o yes yo yes yns es yes ys yes yes yo yos os yes yes yno no o yes no yes o yesyes yo no nes es os es yes os yes yes es eses ys yes yes no yes yes yes yes yes yo yno s yos no yes yes ys yes yes yes yes yes yes ys o yo yo yes o yes o no no yes y o yes yes yo yes yes yes yses yes yes yes yes ysyes yes yes yo s yo yno yes yes yo yes yes es yo es es yes yo no yes yes yes ys yes yo yo yso yo y o yso yes yes yes no o ono o no s s es yos yo yes no no es yes yes n yes yso yes y es yes yes o o ns yes yes ys yesyes yes no es yos yes ys es yeses yes o yo yos yes yes ys o oyes yes ys s yes o no nes es yes yes yes es yo yes o es yes yes yo yes yes oyes yo yes yes nosyes ys o yesyes yes yes yes yo yes soyes yes yo yoysyes yoes yes y es yes yesyes yno no yes yo yes yes no oyes yes yes yo yes yes es no no yes yes ys yes yo yes yes yes es yes yes es yes yes o ys os es yes yos ysyes yes yes yesyes yes yes es yes es yes yes yes no yes yo no no yes yes yoes yo yes yoyes yeo yes yes ysyes yesyes yes yes y eos yes yo no yes ys yes yes yes yes yes yes ysyes yes yes no yes yso yo no nes yes yo ono yns yes os yes yos yses yo yes yos yes yses yes yo o yes yes yo n y es yns yes es no nes o yes yes yes no nes ys o oyes soyes yes es ys no noyes ys y es yos ysos ono o o yes yo yes o yo yes yes yes yes yes yes yo yes y es yes ys yses yes s yos ys yes es yoyoes yes no no es ys yeso yesyes yes y no n yes es yes es es es es yes s es es es es n s y\n",
            "\n",
            "------------------\n"
          ]
        }
      ]
    }
  ]
}